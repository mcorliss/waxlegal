---
layout: post
title: "AI Safety Project: A Hearing"
date: 2025-05-09
excerpt_separator: <!--more-->
---

Yesterday, I attended a hearing of the Senate Committee on Commerce, Science, & Transportation titled, "[Winning the AI Race: Strengthening U.S. Capabilities in Computing and Innovation](https://www.commerce.senate.gov/2025/5/winning-the-ai-race-strengthening-u-s-capabilities-in-computing-and-innovation_2))" (a framing with some significance to AI safety).<!--more-->  There were four witnesses: 
- [Sam Altman](https://en.wikipedia.org/wiki/Sam_Altman) (CEO of OpenAI),
- [Lisa Su](https://en.wikipedia.org/wiki/Lisa_Su) (CEO of AMD),
- Michael Intrator (CEO of [CoreWeave](https://en.wikipedia.org/wiki/CoreWeave)), and
- [Brad Smith](https://en.wikipedia.org/wiki/Brad_Smith_(American_lawyer)) (President of Microsoft).

These are pretty important people in the tech world, and it was clear to me why three of the four would be haled before congress on this topic. But, as you might be able to tell by the absence of a wikipedia link in the list above, Michael Intrator stands out.  CoreWeave didn't seem on par with OpenAI, AMD, and Microsoft -- in fact I'd never heard of it.  But it quickly became apparent why Mr. Intrator was there.

CoreWeave started as a cryptocurrency mining company, but pivoted to cloud infrastructure after the 2018 cryptocurrency crash -- it has since grown into a major provider of cloud-based GPUs, perfect for the AI industry's needs.  So between the four witnesses, you have the full stack of AI development: chip makers (AMD), a chip consumers (CoreWeave), and compute consumers (OpenAI/Microsoft).

The framing of the hearing in terms of 'winning' was apparent from the outset, as all the witnesses confirmed in their opening remarks: this is a race, and America needs to win.  This framing set the tone for their testimony, where they emphasized acceleration at every turn.  Their concerns were about building more, faster, more efficient, etc.

Even discussons of AI regulation were often framed in terms of setting the standard for regulation globally. The companies were all in favor of regulating AI, but they saw AI regulation as a way of *removing* barriers to faster development.  Multiple witnesses (prompted by Senators' questions) explained that state laws are becoming a problem, and a federal law would preempt them to make compliance easier, thereby letting the companies get on with it.  State laws were also compared to the European approach, as an example of the kind of regulation they do not want -- pre-approval, precautionary principle, etc.  Smith offered privacy law as an example of what will happen if Congress doesn't regulate AI: the US failed to pass comprehensive privacy legislation, and as a result most companies default to following the GDPR.  Passing light-touch AI regulation would influence the way the rest of the world regulates AI.

Democrats seemed more concerned about the risks posed by AI, askng questions about hallucination, copyright, product evaluation, antisemitism, environmental impact, social disruption, energy costs, and deepfakes.  But Republicans had their concerns as well, raising concerns about threats AI poses to children, illicit content, and privacy.  The witnesses responses were roughly the same on all of these: yes, it's a problem, but we're working on it.  The exceptions stood out:
- On copyright, Brad Smith argued that Intellectual Property is about line-drawing, and it isn't a given where the line should be drawn between publishers and AIs.
- On children/content restriction/antisemitism/privacy, Sam Altman stated that OpenAI's position is to allow adult users broad freedom to use the produce as they choose, and that AI is different-in-kind from previous technologies on questions of privacy and freedom of speech, because AI will "get to know you".

Concerns expressed by the witnesses that stood out were on supply chains and immigration.  Their concerns were noteworthy for being at odds with current Executive policy, for the unanimous and unequivocal support from the witness, and not least because the Republican Senators seemed to agree with the implications. There was an 'audience of one' feel to watching each witness, in response to leading questions from Republican lawmakers, describe how they needed global partners, how they needed materials and products from abroad in order to support their domestic businesses, how they needed access to foreign markets in order to ensure American dominance of the technology, and how they needed to attract foreign researchers to the US to continue the rate of progress they'd achieved so far.  They also suggested, again in response to leading questions, that if the American environment remained hostile, they would take their business elsewhere.

Existential risk was not discussed, but it seemed to bracket the questioning.  Early, Senator Klobuchar quoted David Brooks as saying that "we can't know if AI is leading us to heaven or hell", arguing for the need for guardrails.  And towards the end of the meeting, Senator Fetterman, after briefly fawning over Sam Altman's celebrity, asked him to address, "What about the singularity?"  I found Altman's response strangely moving, so I'll end with it:

>I am incredibly excited about the rate of progress, but I also am cautious and I would say, like... I don't know, I feel small next to it, or something? I think this is beyond something that we all fully yet understand where it's going to go, this is- this is I believe among the biggest -- maybe it will turn out to be the biggest -- technological revolutions humanity will have ever produced.  And I feel privileged to be here, I feel curious and interested in what's going to happen. 
>
>But I do think things are going to change quite substantially.  I think humans have a wonderful ability to adapt, and things that seem amazing will become the new normal very quickly, we will figure out how to use these tools to just do things we could never do before, and I think it will be quite extraordinary.  But these are going to be tools that are capable of things that we can't quite wrap our heads around.
>
>And some people call that -- you know, as these tools start helping us to create next- future iterations -- some people call that the singularity, some people call that the takeoff; whatever it is, it feels like a sort of new era of human history. And I think it's tremendously exciting that we get to live through that, and I think we can make it a wonderful thing.
>
>But, we've go to approach it with humility, and some caution."

